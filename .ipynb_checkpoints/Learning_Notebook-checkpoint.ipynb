{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2dSyboSFRR7",
    "outputId": "8da10d6f-d2a2-4ee0-919f-bce5171ec8f3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import sklearn.ensemble as ske \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, linear_model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hp1p2lOkFWh6"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', sep='|') #generate df as data\n",
    "X = data.drop(['Name', 'md5', 'legitimate'], axis=1).values #now droping some coloumns as axis 1(mean coloumn) and will show the values in the rows\n",
    "y = data['legitimate'].values #values of legitimate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FfJbUM_Fok3",
    "outputId": "2cb57836-408f-4adc-a02a-39945d5a4830"
   },
   "outputs": [],
   "source": [
    "print('Researching important feature based on %i total features\\n' % X.shape[1])# shape() is use in pandas to give number of row/column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn: Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection using Trees Classifier\n",
    "#### - ExtraTreesClassifier\n",
    "#### - RandomForestClassifier\n",
    "#### - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsel = ske.ExtraTreesClassifier().fit(X, y)\n",
    "#fsel = ske.RandomForestClassifier().fit(X, y)\n",
    "#fsel = DecisionTreeClassifier().fit(X, y)\n",
    "model = SelectFromModel(fsel, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "nb_features = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1L8yAxiuInm_"
   },
   "outputs": [],
   "source": [
    "#fsel = ske.ExtraTreesClassifier(n_estimators=250, random_state=7).fit(X, y)\n",
    "#fsel = ske.RandomForestClassifier(n_estimators=250, random_state=7).fit(X, y)\n",
    "#fsel = DecisionTreeClassifier(random_state=7).fit(X, y)\n",
    "#model = SelectFromModel(fsel, prefit=True)\n",
    "#X_new = model.transform(X)\n",
    "#nb_features = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09c-w3X6Iqjz"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.2)#now converting in training and testing data in 20% range hahhahaha ! as total x is 138047 and testing is 138047*0.2=27610 :)\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8_9xscMIxRe",
    "outputId": "e053fe2c-b630-4ca0-e5bb-262912229e00"
   },
   "outputs": [],
   "source": [
    "print('%i features identified as important:' % nb_features) #as mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE4HPHuXI6ys",
    "outputId": "a041b671-52c7-4d97-8e54-f656bff24c74",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#important features sored\n",
    "indices = np.argsort(fsel.feature_importances_)[::-1][:nb_features]\n",
    "for f in range(nb_features):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, data.columns[2+indices[f]], fsel.feature_importances_[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9R0SCMRrI_WL"
   },
   "outputs": [],
   "source": [
    "# mean adding to the empty 'features' array the 'important features'\n",
    "for f in sorted(np.argsort(fsel.feature_importances_)[::-1][:nb_features]):#[::-1] mean start with last towards first \n",
    "    features.append(data.columns[2+f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "        \"DecisionTree\": tree.DecisionTreeClassifier(max_depth=10),\n",
    "    \n",
    "        \"RandomForest\": ske.RandomForestClassifier(n_estimators=50),\n",
    "    \n",
    "        #\"GradientBoosting\": ske.GradientBoostingClassifier(n_estimators=50),\n",
    "        #AdaBoost\": ske.AdaBoostClassifier(n_estimators=100),\n",
    "        #KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "       #\"LogisticRegression\":LogisticRegression(),\n",
    "       #\"Perceptron\": Perceptron(),\n",
    "       #\"DecisionTreeClassifier\": tree.DecisionTreeClassifier(min_samples_split=10),\n",
    "       #\"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "       #\"BaggingClassifier\": ske.BaggingClassifier(n_estimators=50),\n",
    "        #\"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "        #\"SVC\":SVC(kernel='linear'),\n",
    "        #\"GaussianProcessClassifier\": GaussianProcessClassifier(),\n",
    "        \n",
    "        \"GNB\": GaussianNB()\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "print(\"\\nNow testing algorithms\")\n",
    "for algo in algorithms:\n",
    "    clf = algorithms[algo]\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"%s : %f %%\" % (algo, score*100))\n",
    "    results[algo] = score\n",
    "    #print(f'{a[1]:20} score: {score:.04f}')\n",
    "    #print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    #print(metrics.classification_report(y_test, y_pred))\n",
    "    #print('-' * 100)\n",
    "\n",
    "print(results)\n",
    "print(f'best score = {max(results)}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "6DKQefCOJIpH",
    "outputId": "91d7ef0a-9bdb-4667-d3d9-fb38aac97e6e"
   },
   "outputs": [],
   "source": [
    "winner = max(results, key=results.get)\n",
    "print('\\nWinner algorithm is %s with a %f %% success' % (winner, results[winner]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "cA-Zn5BUJwtR",
    "outputId": "b2269b5e-b0f4-4237-dd19-3d6177f283c3"
   },
   "outputs": [],
   "source": [
    "# Save the algorithm and the feature list for later predictions\n",
    "print('Saving algorithm and feature list in classifier directory...')\n",
    "joblib.dump(algorithms[winner], 'classifier/classifier.pkl')\n",
    "open('classifier/features.pkl', 'wb').write(pickle.dumps(features))\n",
    "print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "RgBDOa0zJ4Ft",
    "outputId": "34fca9fe-73d3-46db-dd46-2578e14b24b3"
   },
   "outputs": [],
   "source": [
    "# Identify false and true positive rates\n",
    "clf = algorithms[winner]\n",
    "res = clf.predict(X_test)\n",
    "mt = confusion_matrix(y_test, res)\n",
    "print(\"False positive rate : %f %%\" % ((mt[0][1] / float(sum(mt[0])))*100))\n",
    "print('False negative rate : %f %%' % ( (mt[1][0] / float(sum(mt[1]))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIbrsaEdK4lP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Learning_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
